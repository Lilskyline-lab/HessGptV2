# Guide de DÃ©marrage Rapide - SystÃ¨me d'Instruction Tuning

## âœ… SystÃ¨me OpÃ©rationnel !

Votre systÃ¨me d'instruction tuning pour LLM est maintenant **entiÃ¨rement configurÃ© et fonctionnel**.

## ğŸ¯ Fonctionnement Automatique

**Vous n'avez RIEN Ã  faire pendant l'entraÃ®nement** - le systÃ¨me fonctionne de maniÃ¨re complÃ¨tement automatique :

1. âœ… Les donnÃ©es sont automatiquement chargÃ©es depuis 3 sources
2. âœ… L'instruction tuning est appliquÃ© automatiquement  
3. âœ… Le formatage se fait selon le template choisi
4. âœ… L'entraÃ®nement dÃ©marre et se termine seul
5. âœ… Le modÃ¨le est sauvegardÃ© automatiquement

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ data/                          # VOS DONNÃ‰ES ICI
â”‚   â”œâ”€â”€ example_instructions.json  # Exemples fournis (10 Q&A)
â”‚   â””â”€â”€ README.md                  # Documentation des formats
â”œâ”€â”€ training/                      # Code d'entraÃ®nement
â”‚   â”œâ”€â”€ TrainWithRealDataSet.py   # Script principal (DÃ‰JÃ€ CONFIGURÃ‰)
â”‚   â”œâ”€â”€ Model/                     # Architecture GPT-2
â”‚   â””â”€â”€ Tokenizer/                 # Tokenizer BPE
â”œâ”€â”€ utils/                         # Outils
â”‚   â””â”€â”€ instruction_tuning.py     # Module d'instruction tuning
â””â”€â”€ saved_models/                  # ModÃ¨les entraÃ®nÃ©s
    â””â”€â”€ my_llm/                    # Votre modÃ¨le
```

## ğŸš€ Comment Utiliser

### 1. Ajouter Vos Propres DonnÃ©es (Optionnel)

CrÃ©ez simplement un fichier dans `data/` :

**Format JSON :**
```json
[
  {
    "human": "Votre question",
    "assistant": "La rÃ©ponse"
  }
]
```

**Format JSONL :**
```jsonl
{"human": "Question 1", "assistant": "RÃ©ponse 1"}
{"human": "Question 2", "assistant": "RÃ©ponse 2"}
```

**Format CSV :**
```csv
human,assistant
"Question 1","RÃ©ponse 1"
"Question 2","RÃ©ponse 2"
```

### 2. DÃ©marrer l'EntraÃ®nement

Le workflow est dÃ©jÃ  configurÃ© et s'exÃ©cute automatiquement !

Pour relancer manuellement :
```bash
python training/TrainWithRealDataSet.py
```

### 3. Modifier les ParamÃ¨tres (Optionnel)

Ã‰ditez `training/TrainWithRealDataSet.py`, ligne ~795 :

```python
trainer.train_one_cycle(
    num_articles=5,          # Nombre d'articles Wikipedia
    qa_per_article=3,        # Q&A par article
    num_dialogues=30,        # Dialogues OASST1
    epochs=2,                # Ã‰poques d'entraÃ®nement
    batch_size=4,            # Taille du batch
    lr=5e-5,                 # Learning rate
    use_custom_data=True     # Utiliser vos donnÃ©es
)
```

### 4. Changer le Template d'Instruction (Optionnel)

Ligne ~764 dans le mÃªme fichier :

```python
trainer = ContinuousTrainer(
    # ...
    instruction_template="chat_bot"  # Changez ici
)
```

**Templates disponibles :**
- `chat_bot` (dÃ©faut) : `Human: {question}\nBot: {answer}`
- `alpaca` : Format Alpaca standard
- `qa` : `Question: {q}\nAnswer: {a}`
- `llama2` : Format Llama 2 Chat
- `vicuna` : Format Vicuna

## ğŸ“Š RÃ©sultats du Premier EntraÃ®nement

âœ… **EntraÃ®nement terminÃ© avec succÃ¨s !**

- **96 exemples** formatÃ©s avec instruction tuning
  - 30 exemples personnalisÃ©s (data/example_instructions.json)
  - 42 paires Q&A depuis Wikipedia (5 articles)
  - 24 dialogues depuis OASST1
- **2 Ã©poques** complÃ©tÃ©es
- **Loss** : 7.54 â†’ 6.56 (diminution de 13%)
- **ModÃ¨le sauvegardÃ©** : `saved_models/my_llm/model.pt`

## ğŸ“ Sources de DonnÃ©es

### 1. DonnÃ©es PersonnalisÃ©es
- Fichiers dans `data/`
- Formats : JSON, JSONL, CSV
- **Automatiquement dÃ©tectÃ©s et chargÃ©s**

### 2. Wikipedia
- Articles alÃ©atoires en franÃ§ais (ou anglais)
- CatÃ©gorisation automatique (science, histoire, gÃ©ographie, etc.)
- GÃ©nÃ©ration de Q&A contextuelles

### 3. OASST1 (Hugging Face)
- Dataset de dialogues conversationnels
- 84,437 conversations disponibles
- Filtrage par langue automatique

## ğŸ”§ Commandes Utiles

**Voir les statistiques :**
Le systÃ¨me affiche automatiquement les stats aprÃ¨s chaque cycle.

**Relancer l'entraÃ®nement :**
```bash
python training/TrainWithRealDataSet.py
```

**Tester le module d'instruction tuning :**
```bash
python utils/instruction_tuning.py
```

## ğŸ’¡ Prochaines Ã‰tapes SuggÃ©rÃ©es

1. **Ajoutez vos propres donnÃ©es** dans `data/`
2. **Augmentez les Ã©poques** pour un meilleur entraÃ®nement
3. **Testez diffÃ©rents templates** d'instruction
4. **ImplÃ©mentez LoRA/QLoRA** pour un fine-tuning plus efficace
5. **Ajoutez un systÃ¨me d'Ã©valuation** automatique

## ğŸ“ Notes Importantes

- âš¡ **Aucune intervention manuelle nÃ©cessaire** pendant l'entraÃ®nement
- ğŸ”„ Les donnÃ©es sont rÃ©pÃ©tÃ©es 3Ã— pour renforcer l'apprentissage
- ğŸ’¾ Le modÃ¨le est sauvegardÃ© automatiquement aprÃ¨s chaque cycle
- ğŸ“Š L'historique d'entraÃ®nement est conservÃ© dans `saved_models/my_llm/training_history.json`
- ğŸ—‚ï¸ Les sujets traitÃ©s sont trackÃ©s dans `saved_models/my_llm/trained_topics.json`

## â“ Questions FrÃ©quentes

**Q: Puis-je utiliser mes propres donnÃ©es uniquement ?**
R: Oui ! Mettez `use_custom_data=True` et `num_articles=0, num_dialogues=0`

**Q: Comment changer la langue ?**
R: Modifiez `language='fr'` en `language='en'` dans le ContinuousTrainer

**Q: OÃ¹ est sauvegardÃ© le modÃ¨le ?**
R: Dans `saved_models/my_llm/model.pt`

**Q: Comment voir les logs d'entraÃ®nement ?**
R: Ils s'affichent automatiquement dans la console pendant l'exÃ©cution

## ğŸ‰ FÃ©licitations !

Votre systÃ¨me d'instruction tuning est **100% opÃ©rationnel** et **entiÃ¨rement automatisÃ©** !
