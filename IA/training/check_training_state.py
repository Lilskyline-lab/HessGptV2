#!/usr/bin/env python3
"""
Script de v√©rification d'√©tat d'entra√Ænement - VERSION CORRIG√âE
Usage: python check_training_state.py
#check_training_state.py
V√©rifie les fichiers avec NOMS FIXES:
- checkpoint.pt : √âtat d'entra√Ænement actuel
- model.pt : Mod√®le fusionn√©
- best_model.pt : Meilleur mod√®le
"""
import sys
import os
from pathlib import Path
import torch

# Chemins
CHECKPOINT_DIR = Path("./IA/saved_models/my_llm/checkpoints")
MODEL_DIR = Path("./IA/saved_models/my_llm")

def format_size(bytes_size):
    """Formate la taille en unit√©s lisibles"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.2f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.2f} TB"

def check_training_state():
    """V√©rifie et affiche l'√©tat d'entra√Ænement complet"""
    print("\n" + "="*70)
    print("üîç V√âRIFICATION √âTAT D'ENTRA√éNEMENT")
    print("="*70)
    
    # ========================================
    # 1. V√âRIFIER checkpoint.pt (priorit√©)
    # ========================================
    checkpoint_path = CHECKPOINT_DIR / "checkpoint.pt"
    
    if checkpoint_path.exists():
        print(f"\n‚úÖ CHECKPOINT TROUV√â: {checkpoint_path.name}")
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
        except:
            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        # Informations d√©taill√©es
        checkpoint_type = checkpoint.get('checkpoint_type', 'unknown')
        timestamp = checkpoint.get('timestamp', 'inconnu')
        epoch = checkpoint.get('epoch', 0)
        batch_idx = checkpoint.get('batch_idx', 0)
        total_batches = checkpoint.get('total_batches_processed', 0)
        
        print(f"\nüìä Type: {checkpoint_type}")
        print(f"üìÖ Date: {timestamp}")
        print(f"üìÅ Taille: {format_size(checkpoint_path.stat().st_size)}")
        
        print(f"\nüî¢ Progression:")
        print(f"   ‚Ä¢ √âpoque: {epoch}")
        print(f"   ‚Ä¢ Batch actuel: {batch_idx}")
        print(f"   ‚Ä¢ Total batches trait√©s: {total_batches:,}")
        
        print(f"\nüìà M√©triques:")
        print(f"   ‚Ä¢ Train Loss: {checkpoint.get('train_loss', 0):.4f}")
        print(f"   ‚Ä¢ Val Loss: {checkpoint.get('val_loss', 0):.4f}")
        print(f"   ‚Ä¢ Best Val Loss: {checkpoint.get('best_val_loss', float('inf')):.4f}")
        
        # Estimation de la progression
        if total_batches > 0:
            batch_size = 8  # Valeur par d√©faut
            estimated_examples = total_batches * batch_size
            next_save = 1000 - (batch_idx % 1000)
            
            print(f"\nüìä Estimation:")
            print(f"   ‚Ä¢ Exemples d√©j√† vus: ~{estimated_examples:,}")
            print(f"   ‚Ä¢ Prochaine sauvegarde dans: {next_save} batches")
        
        # V√©rifier si poids LoRA pr√©sents
        if 'lora_state_dict' in checkpoint:
            num_lora_params = sum(p.numel() for p in checkpoint['lora_state_dict'].values())
            print(f"\nüîß LoRA:")
            print(f"   ‚Ä¢ Poids LoRA pr√©sents: {num_lora_params:,} param√®tres")
            lora_cfg = checkpoint.get('lora_config', {})
            print(f"   ‚Ä¢ Rank: {lora_cfg.get('rank', 'N/A')}")
            print(f"   ‚Ä¢ Alpha: {lora_cfg.get('alpha', 'N/A')}")
        
        print(f"\nüí° Pour reprendre l'entra√Ænement:")
        print(f"   python LoRAFineTuning.py")
        print(f"   ‚Üí Reprise automatique √† l'√©poque {epoch}, batch {batch_idx + 1}")
        
    else:
        print(f"\n‚ùå CHECKPOINT ABSENT: {checkpoint_path}")
        print(f"üí° L'entra√Ænement d√©marrera depuis le d√©but")
    
    # ========================================
    # 2. V√âRIFIER model.pt (mod√®le fusionn√©)
    # ========================================
    model_path = MODEL_DIR / "model.pt"
    
    print(f"\n{'='*70}")
    
    if model_path.exists():
        size = format_size(model_path.stat().st_size)
        print(f"‚úÖ MOD√àLE FUSIONN√â: {model_path.name}")
        print(f"   Taille: {size}")
        
        # Essayer de charger pour v√©rifier l'int√©grit√©
        try:
            model_state = torch.load(model_path, map_location='cpu', weights_only=True)
            num_params = sum(p.numel() for p in model_state.values())
            print(f"   Param√®tres: {num_params:,}")
            print(f"   √âtat: ‚úÖ Valide")
        except Exception as e:
            print(f"   √âtat: ‚ö†Ô∏è  Erreur de chargement: {e}")
    else:
        print(f"‚ùå MOD√àLE FUSIONN√â ABSENT: {model_path}")
        print(f"üí° Sera cr√©√© √† la fin de chaque √©poque")
    
    # ========================================
    # 3. V√âRIFIER best_model.pt
    # ========================================
    best_path = CHECKPOINT_DIR / "best_model.pt"
    
    print(f"\n{'='*70}")
    
    if best_path.exists():
        print(f"üèÜ MEILLEUR MOD√àLE: {best_path.name}")
        
        try:
            best = torch.load(best_path, map_location='cpu')
        except:
            best = torch.load(best_path, map_location='cpu', weights_only=False)
        
        print(f"   Val Loss: {best.get('val_loss', 0):.4f}")
        print(f"   √âpoque: {best.get('epoch', 0)}")
        print(f"   Date: {best.get('timestamp', 'inconnu')}")
        print(f"   Taille: {format_size(best_path.stat().st_size)}")
    else:
        print(f"‚ùå MEILLEUR MOD√àLE ABSENT: {best_path}")
        print(f"üí° Sera cr√©√© quand val_loss s'am√©liore")
    
    # ========================================
    # 4. V√âRIFIER lora_weights.pt
    # ========================================
    lora_path = MODEL_DIR / "lora_weights.pt"
    
    print(f"\n{'='*70}")
    
    if lora_path.exists():
        print(f"‚úÖ POIDS LoRA: {lora_path.name}")
        print(f"   Taille: {format_size(lora_path.stat().st_size)}")
        
        try:
            lora_state = torch.load(lora_path, map_location='cpu')
            if 'metadata' in lora_state:
                meta = lora_state['metadata']
                print(f"   Trainable: {meta.get('trainable_params', 0):,}")
                print(f"   Date: {meta.get('timestamp', 'inconnu')}")
        except:
            pass
    else:
        print(f"‚ùå POIDS LoRA ABSENTS: {lora_path}")
    
    # ========================================
    # 5. R√âSUM√â FINAL
    # ========================================
    print(f"\n{'='*70}")
    print("üìã R√âSUM√â")
    print("="*70)
    
    files_status = {
        "checkpoint.pt": checkpoint_path.exists(),
        "model.pt": model_path.exists(),
        "best_model.pt": best_path.exists(),
        "lora_weights.pt": lora_path.exists()
    }
    
    print(f"\nüìÅ Fichiers pr√©sents:")
    for filename, exists in files_status.items():
        status = "‚úÖ" if exists else "‚ùå"
        print(f"   {status} {filename}")
    
    all_present = all(files_status.values())
    
    if all_present:
        print(f"\n‚úÖ SYST√àME COMPLET - Pr√™t pour reprise ou d√©ploiement")
    elif files_status["checkpoint.pt"]:
        print(f"\n‚ö†Ô∏è  REPRISE POSSIBLE - checkpoint.pt pr√©sent")
        print(f"   Les fichiers manquants seront recr√©√©s automatiquement")
    else:
        print(f"\n‚ùå NOUVEL ENTRA√éNEMENT - Aucun checkpoint")
        print(f"   L'entra√Ænement d√©marrera depuis z√©ro")
    
    # V√©rifier l'espace disque disponible
    try:
        import shutil
        total, used, free = shutil.disk_usage(CHECKPOINT_DIR.parent)
        print(f"\nüíæ Espace disque:")
        print(f"   Total: {format_size(total)}")
        print(f"   Utilis√©: {format_size(used)}")
        print(f"   Libre: {format_size(free)}")
        
        if free < 1024**3:  # Moins de 1GB
            print(f"   ‚ö†Ô∏è  ATTENTION: Espace faible!")
    except:
        pass
    
    print("\n" + "="*70 + "\n")

if __name__ == "__main__":
    check_training_state()
